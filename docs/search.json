[
  {
    "objectID": "topics/IT/git.html",
    "href": "topics/IT/git.html",
    "title": "How can I link my project with github?",
    "section": "",
    "text": "Create a GitHub repository (if you haven’t already):\n\nGo to github.com and log in\nClick the “+” icon in the top right, select “New repository”\nName your repository (e.g., “quarto-shinylive-project”)\nChoose public or private\nDon’t initialize it with README or other files if you already have local content\nClick “Create repository”\n\nLink your local project to the GitHub repository:\n# Navigate to your project directory if you're not already there\ncd \"F:/IT/quarto/Quarto Shinylive\"\n\n# Initialize a Git repository if you haven't already\ngit init\n\n# Add your remote GitHub repository\ngit remote add origin https://github.com/Loisi70/shiny.git\n\n# Add your files to Git\ngit add .\n\n# Commit your changes\ngit commit -m \"Initial commit\"\n\n# Push to GitHub detault branch \"main\" or \"master\" if \"master\" is default branch\ngit push -u origin main  \n\n\nAuthentication\n\nGenerate a Personal Access Token (PAT) on GitHub:\n\nGo to GitHub.com and log in\nClick your profile picture in the top-right → Settings\nScroll down to “Developer settings” in the left sidebar\nClick “Personal access tokens” → “Tokens (classic)”\nClick “Generate new token” → “Generate new token (classic)”\nGive it a descriptive name like “Local Git operations”\nSelect scopes (at minimum, select “repo” for full repository access)\nClick “Generate token”\n\nIMPORTANT: Copy the token immediately! GitHub will only show it once\nUse your token for authentication:\n\nWhen you push to GitHub next time, use your token as the password\nYour username remains the same, but instead of your GitHub password, enter the token\n\nStore credentials so you don’t need to enter them each time (optional):\ngit config --global credential.helper store\nThen the next time you enter your credentials, Git will remember them.\n\n\n\nbash git commands\n\n\n\nCommand\nDescription\n\n\n\n\nls\nlists unhidden objects: will not display .git as this is hidden\n\n\nls -a\nwill display all incl. hidden files such as .git\n\n\ngit –version\nreturns git version\n\n\nnano report.md\nopens text editor: ctrl + O and Ctrl + x to save\n\n\npwd\nprint working directory\n\n\necho\nechoing something to a file,\n&gt;&gt; appends to the file and\n&gt; overwrites the file\necho “49,M,No,Yes,Never,Yes,Yes,No” &gt;&gt; mental_health_survey.csv\n\n\ngit add report.md\ngit add .\nadds the file to the staging area\nadds all files to the staging area\n\n\ngit commit -m “Text”\nmakes a commit with a log message\n\n\ngit status\nshows file in the staging area\n\n\ngit diff report.md\ngit diff -r HEAD filename\ngit diff -r HEAD\ncompare unstaged file with the last committed version\ncompare as staged file with the last commited version\ncompare all staged files with the last committed version\n\n\ngit log\nshows all commits made in chronological order\n\n\ngit show 36b761e4\nusing the 6-8 first characters of the hash, made changes are shown\n\n\ngit show HEAD~3\nshows the 4 last versions\n\n\ngit diff 34f4bd88 186398f\ngit diff Head~3 Head~2\nwill show the changes between two commits\nwill also show the changes between two commits\n\n\ngit annotate report.md\n:\nwill show who made the changes and when\n“:” indicates that there is more information that can be accessed by hitting the space key\n\n\ngit reset HEAD report.md\ngit reset HEAD\nunstage the report.md file from staging area\nunstage all files from staging area\n\n\ngit checkout – report.md\ngit checkout .\ngit checkout dc9d8fac report.md\ngit checkout Head~2 report.md\nreset UNSTAGED report.md to the version of the last commit\nreset UNSTAGED all files to the versions of the last commit\nreset report.md to this particular version\nreset report.md to this particular version\n\n\ngit log -3\ngit log -3 report.md\ngit log –since=‘Apr 2 2022’\ngit log –since=‘Apr 2 2022’\n–until=‘Apr 11 2022’\nshow last 3 logs\nshow last 3 logs for report.md\nshow log with changes since 2nd of April 2022\nwill show changes in range\n\n\ngit clean -n\ngit clean -f\nlist all untracked files\ndelete these untracked files (cannot be undone!!!)\n\n\ngit config –list\ngit config –list –local\ngit config –list –global\ngit config –list –system\ngit config –global (setting value)\n\n\ngit config –global alias.st\ngit config –global –list\nshow config settings\nsettings for the one specific project\nsettings for all of our projects\nsettings for every users on this computer\nwill allow changing the setting:\ngit config –global user.email alois.alig@gmx.ch\ngit config –global user.name ‘Alois Alig’\ncreates an alias ‘st’ for the ‘status’:–&gt; ‘git st’ = ‘git\nlists what is in the’.gitconfig’ file, for # example aliases\n\n\nnano .gitignore\nlist files to ignore whereas * acts as a wildecard\n\n\ngit checkout -b report\ncreate a branche called report\n\n\ngit checkout report\nswitch to the report branch\n\n\ngit branch\nlist the branches\n\n\ngit diff main summary-statistics\nshow difference between branches\n\n\ngit merge source destination\nmerge from source branch to destinantion\n\n\ngit init\nturn the active directory into a repo\n–&gt; do not created nested repos (repo in a repo)!\n\n\ngit init repo1\ncd repo1\ngit status\ncreate a new repo “repo1” in the current directory\nchange directory to “repo1”\nshow the status of newly created repo “repo1”\n\n\ngit clone (url)\ngit clone /home/repo new_repo\nclone a repo from url\nto clone locally\n\n\ngit remote -v\nshows the remote source verbose\n\n\ngit remote add george https://github.com/george_datacamp/repo",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "How can I link my project with github?"
    ]
  },
  {
    "objectID": "topics/index.html",
    "href": "topics/index.html",
    "title": "Topics",
    "section": "",
    "text": "Topics\nA list of technical topics.",
    "crumbs": [
      "Home",
      "Topics"
    ]
  },
  {
    "objectID": "topics/IT/mdx.html",
    "href": "topics/IT/mdx.html",
    "title": "mdx notes",
    "section": "",
    "text": "Notes taken from https://www.youtube.com/watch?v=FqlDM_HzkO4",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "mdx notes"
    ]
  },
  {
    "objectID": "topics/IT/mdx.html#introduction",
    "href": "topics/IT/mdx.html#introduction",
    "title": "mdx notes",
    "section": "",
    "text": "Notes taken from https://www.youtube.com/watch?v=FqlDM_HzkO4",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "mdx notes"
    ]
  },
  {
    "objectID": "topics/IT/mdx.html#running-code",
    "href": "topics/IT/mdx.html#running-code",
    "title": "mdx notes",
    "section": "Running Code",
    "text": "Running Code\nIn order to return the members of a dimension . MEMBERS or .CHILDREN can be used. They both will return the same results. Without .MEMBERS or .CHILDREN the default ALL will be returned\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, --0\n  [Product].[Category].MEMBERS ON ROWS --1\n  --[Product].[Category].CHILDREN ON ROWS --1\nFROM\n  [Adventure Works]\n  \n\nNON EMPTY\nKeyword will suppress empty rows:\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, --0\n  \n  NON EMPTY\n  \n  (\n    [Product].[Category].MEMBERS,\n    [Product].[Subcategory].MEMBERS \n  )ON ROWS --1\nFROM\n  [Adventure Works]\n\n\nORDER\nOptions are DESC, ASC and BDESC, BASC where ase DESC, ASC will order within the hierarchy.\nIn contrast, BDESC, BASC will break the hierarchie\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, --0\n  \n  NON EMPTY\n  ORDER(\n      (\n        [Product].[Category].MEMBERS,\n        [Product].[Subcategory].MEMBERS \n      ),\n      [Measures].[Internet Sales Amount],\n      DESC) ON ROWS --1\nFROM\n  [Adventure Works]\nWHERE\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, --0\n  \n  NON EMPTY\n  ORDER(\n      (\n        [Product].[Category].MEMBERS,\n        [Product].[Subcategory].MEMBERS \n      ),\n      [Measures].[Internet Sales Amount],\n      DESC) ON ROWS --1\nFROM\n  [Adventure Works]\nWHERE\n  [Product].[Color].&[Blue] -- this is acting as a slicer \"blue will however not be                             -- visible in the tuple\"\nTo see blue in the result set the slicer has to be part of the result set as a filter:\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, --0\n  \n  NON EMPTY\n  ORDER(\n      (\n        [Product].[Category].MEMBERS,\n        [Product].[Subcategory].MEMBERS, \n        [Product].[Color].&[Blue]  --this is acting as a filter \"blue\" is now                                         --visible in the tuple\"\n      ),\n      [Measures].[Internet Sales Amount],\n      DESC) ON ROWS --1\nFROM\n  [Adventure Works]\n\nTo slice on two items\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, --0\n  \n  NON EMPTY\n  ORDER(\n      (\n        [Product].[Category].MEMBERS,\n        [Product].[Subcategory].MEMBERS \n      ),\n      [Measures].[Internet Sales Amount],\n      DESC) ON ROWS --1\nFROM\n  [Adventure Works]\nWHERE -- we need a set rather than a tuple hence {}\n  {\n    ([Product].[Color].&[Blue],\n     [Product].[Color].&[Black])\n  }\n\n/* this will fail as we have twice the same hierarchie in the same TUPLE  \nWHERE\n  ([Product].[Color].&[Blue],\n   [Product].[Color].&[Black])\n*/\nAdding columns\nSELECT\n  NON EMPTY --&lt;---\n    ([Date].[Calendar Year].MEMBERS,)\n     [Measures].[Internet Sales Amount]) ON COLUMNS, --0\n  \n  NON EMPTY\n  ORDER(\n      (\n        [Product].[Category].MEMBERS,\n        [Product].[Subcategory].MEMBERS \n      ),\n      [Measures].[Internet Sales Amount],\n      DESC) ON ROWS --1\nFROM\n  [Adventure Works]\nWHERE \n  {\n    ([Product].[Color].&[Blue],\n     [Product].[Color].&[Black])\n  }\n\n\nUser defined hierarchies vs attribute hierarchies\n\n\n\nThe pyramid indicates user hierarchies, the rectangles indicate attribute hierarchies\n\n\nAttribute hierarchies have one level whereas user hierarchies can have multiple levels.\nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, -- 0\n  [Product].[Product Categories].MEMBERS ON ROWS -- 1\nFROM\n  [Adventure Works]\n“.MEMBERS” on a user defined hierarchie will return all levels.\nTo display the respective level, .CURRENTMEMBER.LEVEL.NAME can be used:\nWITH MEMBER [Measures].[Level Name] AS --&lt;---\n  [Product].[Product Categories].CURRENTMEMBER.LEVEL.NAME --&lt;---\n  \nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, -- 0\n  [Product].[Product Categories].MEMBERS ON ROWS -- 1\nFROM\n  [Adventure Works]\n\nIn order to see the categories only “.CHILDREN” can be used instead of “.MEMBERS”:\nWITH MEMBER [Measures].[Level Name] AS \n  [Product].[Product Categories].CURRENTMEMBER.LEVEL.NAME\n  \nSELECT\n  [Measures].[Internet Sales Amount] ON COLUMNS, \n  [Product].[Product Categories].CHILDREN ON ROWS --&lt;---\nFROM\n  [Adventure Works]\n\n\n\nCreate new measures\nWITH MEMBER [Measures].[Profit] AS                                          --&lt;---\n  [Measures].[Internet Sales Amount] -                                      --&lt;---\n  [Measures].[Internet Total Product Cost], FORMAT_STRING = \"CURRENCY\"      --&lt;---\n  \n  MEMBER [Measures].[Profit Margin] AS --&lt;---\n  [Measures].[Profit] /                                                     --&lt;---\n  [Measures].[Internet Sales Amount], FORMAT_STRING = \"PERCENT\"             --&lt;---\n  \nSELECT\n  {\n    [Measures].[Internet Sales Amount],\n    [Measures].[Internet Total Product Cost],\n    [Measures].[Profit],                                                    --&lt;---\n    [Measures].[Profit Margin]} ON COLUMNS,                                 --&lt;---\n    \n  [Product].[Product Categories].CHILDREN ON ROWS \n\nFROM\n  [Adventure Works]\n\n\nTime intelligence\nWITH MEMBER [Measures].[YTD Demo] AS \n      SUM(\n        YTD([DATE].[Calendar].CURRENTMEMBER),\n        [Measures].[Internet Sales Amount])\n    \n     MEMBER [Measures].[MTD Demo] AS \n      SUM(\n        MTD([DATE].[Calendar].CURRENTMEMBER),\n        [Measures].[Internet Sales Amount])\n     \n     MEMBER [Measures].[Previous Period] AS \n       SUM(\n        [Date].[Calendar].CURRENTMEMBER.PREVMEMBER,\n        [Measures].[Internet Sales Amount])                                     \n\nSELECT\n  {\n    [Measures].[Internet Sales Amount],\n    [Measures].[YTD Demo],\n    [Measures].[MTD Demo]\n  } ON COLUMS,\n  \n  [Date].[Calendar].MEMBERS ON ROWS \n\nFROM\n  [Adventure Works]",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "mdx notes"
    ]
  },
  {
    "objectID": "topics/IT/LLM.html",
    "href": "topics/IT/LLM.html",
    "title": "LLM",
    "section": "",
    "text": "What is Ollama?\nSource: https://blog.cubed.run/llm-zero-to-hero-with-ollama-913e50d6b7f0\nOllama is a platform that simplifies the process of running large language models (LLMs) privately on your own computers without relying on an external vendor. This provides more control, privacy, and flexibility.\n\n\nInstalling Ollama\nInstalling Ollama on your computer is very simple. Just visit the downloads page, select your operating system, and either download the installer and run it (macOS and Windows), or run the provided command on Linux.\nAfter installing run in ollama –version in the terminal to see whether Ollama is running.\nTo download the Llama3.2 model, you only need to run the following command:\nollama pull llama3.2\nNow that we have a model, we can list the models that are available locally with the list command:\nollama list\nNow that we have a model downloaded, we are ready to run it.\n\n\nRunning Models\n\nNon-interactive\nTo run the model, and ask it a question, we can give it a single, non-interactive prompt or start an interactive session where we can have an ongoing string of prompts.\nTo provide a single non-interactive prompt and receive a response use the run command followed by your prompt:\nollama run llama3.2 \"Explain why the sky is blue in a single sentence\" \n\n\nInteractive session\nTo start an interactive session where you can have a running conversation use the run command without a prompt:\nollama run llama3.2\nHere are the commands that we’ll use to download, run and ask Moondream to describe the above picture:\nollama pull moondream \nollama run moondream  \n\n&gt;&gt;&gt; Describe this picture: /Users/robertm/Documents/picture-123.png\n\n\nChecking which models are loaded\nYou can use the ps command to check what models are loaded into memory\nollama ps\n\n\nNative Ollama API With Python\nTo use the Ollama native API with Python, you’ll need to install the “ollama” module:\npip install ollama \nNext, we’ll create a file named “ollama-chat.py” with the following contents:\n\nimport ollama\n\nstream = ollama.chat(\n    model='llama3.2',\n    messages=[{'role': 'user', 'content': 'Tell me a long story about your world'}],\n    stream=True,\n)\n\nfor chunk in stream:\n  print(chunk['message']['content'], end='', flush=True)\n\n\n\nUse OpenAi API\n\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key='boguskey',\n    base_url=\"http://localhost:11434/v1\"\n)\n\ncompletion = client.chat.completions.create(\n    model=\"llama3.2\",\n    temperature=1.0,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\n            \"role\": \"user\",\n            \"content\": \"Write a haiku about recursion in programming.\"\n        }\n    ]\n)\nprint(completion.choices[0].message.content)\n\n\n\nChatGPT like Interface for Ollama with Open WebUI\nUp to this point all of our use of LLMs via Ollama have been either via the command-line or scripts. In this section we’re going to add a ChatGPT like web UI to make using Ollama much easier to use and to provide a lot of additional functionality. For this we’ll be using the excellent Open WebUI that provides a ChatGPT like user interface with features not even available with a ChatGPT Plus subscription.\nInstalling Open WebUI\npip install open-webui\nThat will download the package and all its dependencies it needs to run. After all the packages are installed, you can just start it up and start using it. Run the following command:\nWEBUI_AUTH=False python open-webui serve\nUsing Open WebUI\nAfter you’ve installed Open WebUI via one of the above methods, open up a new web browser tab and navigate to the following URL:\nhttp://127.0.0.1/8080\n\nSelect a model from the “Select a Model” drop down at the top of the window and set it as a default. Llama3.2:latest was selected and set as the default in the above screenshot. At this point you can just start prompting it like you would ChatGPT.\nOpen WebUI Settings\nIf you click on the “User” profile in the lower left of the app, you can access the “settings” interface to customize the system to suit your needs:\n\nThe Open WebUI Workspace\nThe “Workspace” is accessible via the icon in the upper left of the application. It will let you work with models, even create new ones similar to how we did with the Ollama model files in a previous section, let you create a knowledge base of documents that the LLMs can consult, and create a curated set of prompts that can be accessed quickly with a “/” command. You can even create your own tools and functions using Python that the LLMs can call in the Tools and Functions sections:\n\nThe Knowledge portion of the workspace allows you to curate collections of documents that you can query with an LLM by using the “#” symbol and picking the collection to consult. You can optimize how to processes documents (chunk size, embedding model, etc.) in the Open WebUI admistrative settings dialog.\nPulling in content from web pages\nIf you want to pull in some information from a web page into the LLM’s context, use a “#” character followed by a URL like this:\n\nOpen WebUI will read the content of the URL you provided into the LLM’s context window and use it to answer your questions.",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "LLM"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About This Project\nThis knowledge base was built using Quarto."
  },
  {
    "objectID": "resources/references.html",
    "href": "resources/references.html",
    "title": "References",
    "section": "",
    "text": "References\nA collection of external resources and documentation links.",
    "crumbs": [
      "Home",
      "Resources",
      "References"
    ]
  },
  {
    "objectID": "topics/IT/Outlier Detection.html",
    "href": "topics/IT/Outlier Detection.html",
    "title": "Outlier Detection",
    "section": "",
    "text": "Techniques\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nZ-Score Method\nIdentifies outliers based on standard deviations from the mean\n\n\nIQR (Interquartile Range)\nUses quartiles to determine what’s outside the expected range\n\n\nIsolation Forest\nMachine learning algorithm that isolates observations by randomly selecting features\n\n\nLocal Outlier Factor (LOF)\nMeasures local deviation of density with respect to neighbors\n\n\nElliptic Envelope\nAssumes Gaussian distribution and finds points that deviate\n\n\nDBSCAN Clustering\nDensity-based clustering that can identify points in low-density regions\n\n\nModified Z-Score\nMore robust version of Z-score that uses median instead of mean\n\n\nPercentile-based\nUses percentile thresholds to identify extreme values\n\n\nMahalanobis Distance\nMeasures distance accounting for correlations in multivariate data\n\n\n\n\n\nExamples\nImports and seeding data\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate sample data with outliers\nnp.random.seed(42)\n# Generate normal data\nX_normal = np.random.normal(0, 1, (100, 2))\n# Add some outliers\nX_outliers = np.random.uniform(low=-5, high=5, size=(10, 2))\nX = np.vstack([X_normal, X_outliers])\n\n# Create a dataframe for easier manipulation\ndf = pd.DataFrame(X, columns=['feature1', 'feature2'])\n\n# Visualization function\ndef plot_outliers(df, outliers_mask, title):\n    plt.figure(figsize=(5, 3))\n    plt.scatter(df['feature1'], df['feature2'], c=['blue' if not x else 'red' for x in outliers_mask], alpha=0.7)\n    plt.title(title)\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.legend(['Normal', 'Outlier'])\n    plt.show()\n\n\nStatistical (Z-Score)\n\ndef zscore_outliers(df, threshold=3):\n    \"\"\"Detect outliers using Z-score method\"\"\"\n    z_scores = stats.zscore(df)\n    outliers_mask = (np.abs(z_scores) &gt; threshold).any(axis=1)\n    print(f\"Z-Score method detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nIQR (Interquartile Range)\n\ndef iqr_outliers(df, factor=1.5):\n    \"\"\"Detect outliers using IQR method\"\"\"\n    Q1 = df.quantile(0.25)\n    Q3 = df.quantile(0.75)\n    IQR = Q3 - Q1\n    outliers_mask = ((df &lt; (Q1 - factor * IQR)) | (df &gt; (Q3 + factor * IQR))).any(axis=1)\n    print(f\"IQR method detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nIsolation Forest\n\ndef isolation_forest_outliers(df, contamination=0.1):\n    \"\"\"Detect outliers using Isolation Forest\"\"\"\n    model = IsolationForest(contamination=contamination, random_state=42)\n    preds = model.fit_predict(df.values)\n    outliers_mask = preds == -1\n    print(f\"Isolation Forest detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nLocal Outlier Factor (LOF)\n\ndef lof_outliers(df, n_neighbors=20, contamination=0.1):\n    \"\"\"Detect outliers using Local Outlier Factor\"\"\"\n    model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n    preds = model.fit_predict(df.values)\n    outliers_mask = preds == -1\n    print(f\"LOF detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nElliptic Envelope (assumes Gaussian distribution)\n\ndef elliptic_envelope_outliers(df, contamination=0.1):\n    \"\"\"Detect outliers using Elliptic Envelope\"\"\"\n    model = EllipticEnvelope(contamination=contamination, random_state=42)\n    preds = model.fit_predict(df)\n    outliers_mask = preds == -1\n    print(f\"Elliptic Envelope detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nDBSCAN clustering\n\ndef dbscan_outliers(df, eps=0.5, min_samples=5):\n    \"\"\"Detect outliers using DBSCAN\"\"\"\n    # Scale the features\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(df)\n    \n    # Fit DBSCAN\n    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n    clusters = dbscan.fit_predict(scaled_data)\n    \n    # Mark outliers (cluster label -1)\n    outliers_mask = clusters == -1\n    print(f\"DBSCAN detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\nModified Z-Score (more robust to outliers)\n\ndef modified_zscore_outliers(df, threshold=3.5):\n    \"\"\"Detect outliers using Modified Z-score\"\"\"\n    median = df.median()\n    mad = np.median(np.abs(df - median), axis=0)\n    modified_z_scores = 0.6745 * np.abs(df - median) / mad\n    outliers_mask = (modified_z_scores &gt; threshold).any(axis=1)\n    print(f\"Modified Z-Score method detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\nPercentile-based\n\ndef percentile_outliers(df, lower_percentile=0.01, upper_percentile=0.99):\n    \"\"\"Detect outliers using percentile method\"\"\"\n    lower_bound = df.quantile(lower_percentile)\n    upper_bound = df.quantile(upper_percentile)\n    outliers_mask = ((df &lt; lower_bound) | (df &gt; upper_bound)).any(axis=1)\n    print(f\"Percentile method detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nMahalanobis Distance (for multivariate data)\n\ndef mahalanobis_outliers(df, threshold=3.0):\n    \"\"\"Detect outliers using Mahalanobis distance\"\"\"\n    # Calculate mean and covariance\n    mean = np.mean(df, axis=0)\n    cov = np.cov(df.T)\n    \n    # Calculate Mahalanobis distance for each point\n    inv_cov = np.linalg.inv(cov)\n    mahal_dist = []\n    \n    for i in range(df.shape[0]):\n        x = df.iloc[i].values\n        mahal_dist.append(np.sqrt(np.dot(np.dot((x - mean), inv_cov), (x - mean).T)))\n    \n    mahal_dist = np.array(mahal_dist)\n    outliers_mask = mahal_dist &gt; threshold\n    print(f\"Mahalanobis method detected {sum(outliers_mask)} outliers\")\n    return outliers_mask\n\n\n\nRun calculations\n\n# Demonstrate outlier detection methods on sample data\nprint(\"Sample Data Info:\")\nprint(f\"Total points: {len(df)}\")\nprint(f\"Expected outliers: {len(X_outliers)}\")\nprint(\"\\nApplying different outlier detection methods:\")\n\n# Apply all methods and visualize results\noutliers_zscore = zscore_outliers(df)\nplot_outliers(df, outliers_zscore, 'Z-Score Method')\n\noutliers_iqr = iqr_outliers(df)\nplot_outliers(df, outliers_iqr, 'IQR Method')\n\noutliers_iforest = isolation_forest_outliers(df)\nplot_outliers(df, outliers_iforest, 'Isolation Forest Method')\n\noutliers_lof = lof_outliers(df)\nplot_outliers(df, outliers_lof, 'Local Outlier Factor Method')\n\noutliers_elliptic = elliptic_envelope_outliers(df)\nplot_outliers(df, outliers_elliptic, 'Elliptic Envelope Method')\n\noutliers_dbscan = dbscan_outliers(df)\nplot_outliers(df, outliers_dbscan, 'DBSCAN Method')\n\noutliers_mod_zscore = modified_zscore_outliers(df)\nplot_outliers(df, outliers_mod_zscore, 'Modified Z-Score Method')\n\noutliers_percentile = percentile_outliers(df)\nplot_outliers(df, outliers_percentile, 'Percentile Method')\n\noutliers_mahalanobis = mahalanobis_outliers(df)\nplot_outliers(df, outliers_mahalanobis, 'Mahalanobis Distance Method')\n\n# Compare methods with a summary\nmethods = [\n    'Z-Score', 'IQR', 'Isolation Forest', 'LOF', \n    'Elliptic Envelope', 'DBSCAN', 'Modified Z-Score',\n    'Percentile', 'Mahalanobis'\n]\n\noutlier_counts = [\n    sum(outliers_zscore), sum(outliers_iqr), sum(outliers_iforest),\n    sum(outliers_lof), sum(outliers_elliptic), sum(outliers_dbscan),\n    sum(outliers_mod_zscore), sum(outliers_percentile), sum(outliers_mahalanobis)\n]\n\n# Create summary dataframe\nsummary = pd.DataFrame({\n    'Method': methods,\n    'Outliers Detected': outlier_counts\n})\n\nprint(\"\\n------- Summary of Results -------\")\nprint(summary)\n\n# Plot summary\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Method', y='Outliers Detected', data=summary)\nplt.title('Comparison of Outlier Detection Methods')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Real-world example function\ndef detect_outliers_in_real_data(df, columns_to_check=None, method='zscore'):\n    \"\"\"\n    Detect outliers in real-world data using specified method\n    \n    Parameters:\n    -----------\n    df : pandas DataFrame\n        Input data\n    columns_to_check : list or None\n        Columns to check for outliers (numeric only)\n    method : str\n        Outlier detection method ('zscore', 'iqr', 'iforest', 'lof', 'elliptic', \n                                  'dbscan', 'mod_zscore', 'percentile', 'mahalanobis')\n    \n    Returns:\n    --------\n    outlier_indices : numpy array\n        Indices of detected outliers\n    \"\"\"\n    # Select only numeric columns if not specified\n    if columns_to_check is None:\n        columns_to_check = df.select_dtypes(include=[np.number]).columns.tolist()\n    \n    # Extract numeric data for outlier detection\n    data = df[columns_to_check].copy()\n    \n    # Handle missing values\n    data = data.fillna(data.median())\n    \n    # Apply selected method\n    if method == 'zscore':\n        outliers_mask = zscore_outliers(data)\n    elif method == 'iqr':\n        outliers_mask = iqr_outliers(data)\n    elif method == 'iforest':\n        outliers_mask = isolation_forest_outliers(data)\n    elif method == 'lof':\n        outliers_mask = lof_outliers(data)\n    elif method == 'elliptic':\n        outliers_mask = elliptic_envelope_outliers(data)\n    elif method == 'dbscan':\n        outliers_mask = dbscan_outliers(data)\n    elif method == 'mod_zscore':\n        outliers_mask = modified_zscore_outliers(data)\n    elif method == 'percentile':\n        outliers_mask = percentile_outliers(data)\n    elif method == 'mahalanobis':\n        outliers_mask = mahalanobis_outliers(data)\n    else:\n        raise ValueError(f\"Unknown method: {method}\")\n    \n    return np.where(outliers_mask)[0]\n\nSample Data Info:\nTotal points: 110\nExpected outliers: 10\n\nApplying different outlier detection methods:\nZ-Score method detected 4 outliers\nIQR method detected 7 outliers\nIsolation Forest detected 11 outliers\nLOF detected 11 outliers\nElliptic Envelope detected 11 outliers\nDBSCAN detected 18 outliers\nModified Z-Score method detected 4 outliers\nPercentile method detected 8 outliers\nMahalanobis method detected 5 outliers\n\n------- Summary of Results -------\n              Method  Outliers Detected\n0            Z-Score                  4\n1                IQR                  7\n2   Isolation Forest                 11\n3                LOF                 11\n4  Elliptic Envelope                 11\n5             DBSCAN                 18\n6   Modified Z-Score                  4\n7         Percentile                  8\n8        Mahalanobis                  5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample usage with real dataset\n\n# Example usage with real dataset\nfrom sklearn.datasets import fetch_california_housing\n\ndef detect_outliers_in_real_data(df, columns_to_check=None, method='zscore'):\n    \"\"\"\n    Detect outliers in real-world data using specified method\n    \n    Parameters:\n    -----------\n    df : pandas DataFrame\n        Input data\n    columns_to_check : list or None\n        Columns to check for outliers (numeric only)\n    method : str\n        Outlier detection method ('zscore', 'iqr', 'iforest', 'lof', 'elliptic', \n                                  'dbscan', 'mod_zscore', 'percentile', 'mahalanobis')\n    \n    Returns:\n    --------\n    outlier_indices : numpy array\n        Indices of detected outliers\n    \"\"\"\n    # Select only numeric columns if not specified\n    if columns_to_check is None:\n        columns_to_check = df.select_dtypes(include=[np.number]).columns.tolist()\n    \n    # Extract numeric data for outlier detection\n    data = df[columns_to_check].copy()\n    \n    # Handle missing values\n    data = data.fillna(data.median())\n    \n    # Apply selected method\n    if method == 'zscore':\n        outliers_mask = zscore_outliers(data)\n    elif method == 'iqr':\n        outliers_mask = iqr_outliers(data)\n    elif method == 'iforest':\n        outliers_mask = isolation_forest_outliers(data)\n    elif method == 'lof':\n        outliers_mask = lof_outliers(data)\n    elif method == 'elliptic':\n        outliers_mask = elliptic_envelope_outliers(data)\n    elif method == 'dbscan':\n        outliers_mask = dbscan_outliers(data)\n    elif method == 'mod_zscore':\n        outliers_mask = modified_zscore_outliers(data)\n    elif method == 'percentile':\n        outliers_mask = percentile_outliers(data)\n    elif method == 'mahalanobis':\n        outliers_mask = mahalanobis_outliers(data)\n    else:\n        raise ValueError(f\"Unknown method: {method}\")\n    \n    return np.where(outliers_mask)[0]\n\n\n# Load the California Housing dataset\ncalifornia = fetch_california_housing()\ncalifornia_df = pd.DataFrame(california.data, columns=california.feature_names)\n\n# Detect outliers using different methods\noutlier_indices_zscore = detect_outliers_in_real_data(california_df, method='zscore')\noutlier_indices_iforest = detect_outliers_in_real_data(california_df, method='iforest')\n\n# Compare results\nprint(f\"Z-Score detected {len(outlier_indices_zscore)} outliers\")\nprint(f\"Isolation Forest detected {len(outlier_indices_iforest)} outliers\")\n\n# Examine outlier data\nprint(\"\\nOutliers detected by Z-Score:\")\nprint(california_df.iloc[outlier_indices_zscore].describe())\n\nZ-Score method detected 846 outliers\nIsolation Forest detected 2064 outliers\nZ-Score detected 846 outliers\nIsolation Forest detected 2064 outliers\n\nOutliers detected by Z-Score:\n           MedInc    HouseAge    AveRooms   AveBedrms    Population  \\\ncount  846.000000  846.000000  846.000000  846.000000    846.000000   \nmean     7.105330   20.867612    9.769835    1.745016   3321.469267   \nstd      4.114159   13.268692    9.741225    2.148860   3483.526439   \nmin      0.499900    1.000000    1.806122    0.600000      9.000000   \n25%      3.539375   11.000000    5.797817    1.021909    607.500000   \n50%      5.641300   18.000000    7.608804    1.062361   1491.500000   \n75%     10.556525   28.000000    8.837453    1.164484   5729.000000   \nmax     15.000100   52.000000  141.909091   34.066667  35682.000000   \n\n          AveOccup    Latitude   Longitude  \ncount   846.000000  846.000000  846.000000  \nmean      6.332998   35.531962 -119.255414  \nstd      51.041823    2.107363    1.971736  \nmin       0.692308   32.560000 -123.490000  \n25%       2.550517   33.960000 -121.435000  \n50%       2.871611   34.210000 -118.460000  \n75%       3.235143   37.560000 -117.780000  \nmax    1243.333333   41.500000 -114.310000",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "Outlier Detection"
    ]
  },
  {
    "objectID": "topics/IT/pdf-to-markdown.html",
    "href": "topics/IT/pdf-to-markdown.html",
    "title": "pdf-to-markdown",
    "section": "",
    "text": "PDF to Markdown\nSource Article\nConvert any PDF to clean, structured Markdown using a local LLM (Gemma 3 via Ollama) — no cloud APIs, no privacy worries.\nThe idea is simple:\n\nTurn each PDF page into an image.\nSend those images to a local LLM using Ollama, specifically gemma3:12b (gemma3:4b works too).\nAsk the model to extract the readable content in Markdown format.\nSave the result as a .md file you can actually use.\n\n\nInstall newest uv in windows:\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n\nCreate an uv environment\nuv init pdftomd cd pdftomd\n\n\nAdd to the environment the required packages:\nuv pip install pymupdf pillow ollama Make sure you have Ollama installed (otherwise follow instructions in https://ollama.com/download)and running locally, and that gemma3 is pulled:\nollama run gemma3:12b\n\n\nAlternatively if you don’t want to use too much ressources:\nollama run gemma3:4b\nTo run the code in a Python shell which uses the defined uv environment, you do:\nuv run python \nfrom inside the pdftomd folder:\nuv run myscript.py \nLet’s start the code session with:\nimport fitz # PyMuPDF for PDFs import ollama import io from PIL import Image We import the essentials. PyMuPDF (via fitz) is great for page rendering, and Pillow helps convert raw data into proper PNGs.\nStep 1: Convert PDF Pages to Images\ndef convert_pdf_to_images(pdf_path): images = [] doc = fitz.open(pdf_path) # Open the PDF for page_num in range(len(doc)): pix = doc[page_num].get_pixmap() # Render page to pixel map img = Image.frombytes(“RGB”, [pix.width, pix.height], pix.samples) # Convert to PIL image img_buffer = io.BytesIO() img.save(img_buffer, format=“PNG”) # Save as in-memory PNG images.append(img_buffer.getvalue()) # Raw PNG bytes return images This function reads the PDF, converts each page into a high-res image, and stores them in memory as raw PNG bytes — perfect for sending to an LLM that accepts images.\nWhy use raw bytes? Because Ollama supports them directly. No need to write files to disk, which is faster and cleaner.\nStep 2: Ask the LLM to Extract Text\nprompt = “Extract all readable text from these images and format it as structured Markdown.” def query_gemma3_with_images(image_bytes_list, model=“gemma3:12b”, prompt=prompt): response = ollama.chat( model=model, messages=[{ “role”: “user”, “content”: prompt, “images”: image_bytes_list }] ) return response[“message”][“content”] This is where the magic happens. You’re sending the image data to your local Gemma model and asking it to do the heavy lifting.\nBonus: Since everything runs locally, your data never leaves your machine. Great for sensitive documents.\nStep 3: Putting It All Together\npdf_path = “mypdf.pdf” # Replace with your PDF file images = convert_pdf_to_images(pdf_path)\nif images: print(f”Converted {len(images)} pages to images.”)\nextracted_text = query_gemma3_with_images(images)\n\nwith open(\"output.md\", \"w\", encoding=\"utf-8\") as md_file:\n    md_file.write(extracted_text)\nprint(\"\\nMarkdown Conversion Complete! Check `output.md`.\")\nelse: print(“No images found in the PDF.”) This final section ties it all together.\nWe load your PDF. Convert it to images. Feed it to the model. Save the result to output.md. All in one go.\nWhat You Gain ✅ Markdown-ready output, perfect for LLM pipelines, knowledge bases, or just human readability. ✅ Scanned PDF compatibility, thanks to the image-based approach. ✅ Private by default, since all inference runs locally. ✅ Elegant simplicity — no bloated OCR pipelines or brittle PDF parsers. Use Cases to Inspire You\nTurn old scanned textbooks into Markdown for fine-tuning models Build an offline document QA system using local embeddings Feed converted documents into a retrieval-augmented chatbot Summarize meeting notes, scientific papers, or financial reports Create a Markdown knowledge base from PDFs, Word files, etc. Final Thoughts We often chase complexity because we think that’s where the power lies. But sometimes, it’s about removing friction and making things just click.\nThis workflow is fast, local, and smart. It gives you Markdown from virtually any PDF with minimal effort, and it runs in a few seconds with zero cloud dependencies.\nThe full code:\nimport fitz # PyMuPDF for PDFs import ollama import io from PIL import Image\ndef convert_pdf_to_images(pdf_path): images = [] doc = fitz.open(pdf_path) # Open the PDF for page_num in range(len(doc)): pix = doc[page_num].get_pixmap() # Render page to pixel map img = Image.frombytes(“RGB”, [pix.width, pix.height], pix.samples) # Convert to PIL image img_buffer = io.BytesIO() img.save(img_buffer, format=“PNG”) # Save as in-memory PNG images.append(img_buffer.getvalue()) # Raw PNG bytes return images\nprompt = “Extract all readable text from these images and format it as structured Markdown.” def query_gemma3_with_images(image_bytes_list, model=“gemma3:12b”, prompt=prompt): response = ollama.chat( model=model, messages=[{ “role”: “user”, “content”: prompt, “images”: image_bytes_list }] ) return response[“message”][“content”]\nif name == ‘main’:\npdf_path = \"mypdf.pdf\"  # Replace with your PDF file\nimages = convert_pdf_to_images(pdf_path)\n\nif images:\n    print(f\"Converted {len(images)} pages to images.\")\n\n    extracted_text = query_gemma3_with_images(images)\n\n    with open(\"output.md\", \"w\", encoding=\"utf-8\") as md_file:\n        md_file.write(extracted_text)\n    print(\"\\nMarkdown Conversion Complete! Check `output.md`.\")\nelse:\n    print(\"No images found in the PDF.\")\nSave this code under nano pdftomd.py and you can run this with:\nuv run pdftomd.py You can extract text from a single image with:\nimport ollama import base64\ndef image_to_text(image_path, model=“gemma3:12b”, prompt=“Extract text from this image”): with(open(image_path, “rb”) as f: image_data = f.read() response = ollama.chat(model=model, messages=[{“role”: “user”, “content”: prompt, “images”: [image_data]}]) return response[“message”][“content”] And you can improve your results with a better prompt:\nprompt = “Extract all readable text and text chunks from this image” +\n” and format it as structured Markdown.” +\n” Look in the entire image always and try to retrieve all text!” By changing the prompt and asking for another format (e.g. JSON) or asking for other aspects, you could completely change the behavior of this program. That’s the beauty of programs using LLM prompts. (You could e.g. also ask for a translation of the content “And please translate the extracted content to Korean.”).\nHow are you extracting Markdown from PDF files or images so far? What experiences did you make with extractions or PDF to Markdown conversions?\nEpilogue: Using Poppler Instead of PyMuPDF Medium member Milan Agatonovic pointed out correctly that PyMuPDF in the fitz package is not free for commercial use. Thank you, Milan Agatonovic!\nIn the Julia solution equivalent to this article (see below), I used Poppler_jll . We can also use poppler in Python.",
    "crumbs": [
      "Home",
      "Topics",
      "IT",
      "pdf-to-markdown"
    ]
  }
]